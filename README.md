# ğŸš¨ Surveillance Using Vision Transformers (ViTs)

## ğŸ“Œ Introduction

In the ever-evolving landscape of security and surveillance, the need for intelligent and reliable systems has never been greater. Vision Transformers (ViTs), a breakthrough in the field of artificial intelligence, are poised to revolutionize video surveillance, offering unparalleled capabilities for:

- ğŸ¯ Object Detection  
- ğŸ•µï¸â€â™‚ï¸ Action Recognition  
- â— Anomaly Detection  

### Key Benefits:

- âœ… **Enhanced Security**: Detect and respond to threats in real-time  
- ğŸ§  **Actionable Insights**: Get smarter decisions from surveillance data  
- ğŸš« **Reduced False Alarms**: Accurate anomaly classification  
- ğŸš€ **Scalability**: Adapt to future surveillance demands  

---

## ğŸ¯ Objectives

- **Enhanced Security**: Proactively identify and respond to potential threats.
- **Reduced False Alarms**: Minimize disruptions with accurate anomaly detection.
- **Scalable and Future-Proof**: Adapt to evolving surveillance needs.
- **Improved Decision-Making**: Gain actionable insights from surveillance footage.

---

## ğŸ”§ Methodology

1. ğŸ“¥ **Data Collection and Preprocessing**  
2. ğŸ§  **Model Design and Implementation**  
3. ğŸ“Š **Evaluation and Refinement**  
4. ğŸš€ **Integration and Deployment**  
5. âš–ï¸ **Ethical Considerations**

### ğŸ”„ Methodology Block Diagram:

![Methodology](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Block%20Diagram.png)

---

## ğŸ“š Dataset Description

### ğŸ”¹ UCF-Crime
- 128 hours of untrimmed surveillance videos  
- 1900 real-world videos  
- 13 anomaly classes: Abuse, Arrest, Arson, Assault, etc.  
- Ideal for general anomaly detection and activity classification  

### ğŸ”¹ Kinetics-400
- 400 human action classes  
- 400+ clips per class, ~10s duration each  
- Covers human-object and human-human interactions  
- Ideal for action classification and self-supervised learning

---

## ğŸ›ï¸ Theft & Violence in Retail Shops

- **Shrink** is the loss metric in retail due to theft or other causes.
- In 2022, retail shrink hit **$112.1 billion**, up from **$93.9 billion** in 2021.
- Theft (internal & external) makes up **65-70%** of shrink.
- **Organized Retail Crime (ORC)** has become increasingly violent.
  - **81%** report ORC offenders are more violent than previous years.
  - **67%** say violence is increasing year over year.

---

## ğŸ“ˆ Statistics and Visuals

- ğŸ“Š **Statistics**
  
    ![Statistics Screenshot 1](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Statistics%201.png)

    ![Statistics Screenshot 2](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Statistics%202.png)

    ![Statistics Screenshot 3](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Statistics%203.png)

  
- ğŸ”³ **Model Training and Testing Outputs**

  ![Training Screenshot](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Model%20Training.png)
  
- ğŸ› ï¸ **Model Working**
      
      

---

## ğŸ’» Model Architecture

> Vision Transformer (ViT) based architecture is used for:
- Action recognition
- Anomaly detection
- Person classification in video streams

---

## âš™ï¸ Working of My Project

The current project enhances retail surveillance by processing uploaded videos through a **Google Colab-based system**.  
Users upload videos via a **Streamlit web interface**, which triggers the `EnhancedRetailSurveillanceSystem` to analyze up to **100 frames** using **VideoMAE**.  

- ğŸ§ **Person Detection**: Detected using HOG and motion-based methods  
- ğŸ§­ **Tracking**: Implemented with a custom `PersonTracker`  
- ğŸ·ï¸ **Behavior Classification**: Uses a 16-frame buffer to classify behaviors into:  
  - âœ… Normal  
  - â“ Suspicious  
  - ğŸ˜¡ Aggressive  
  - ğŸ’¥ Violence  
  - ğŸ›ï¸ Theft  

### âœ… Output:
- Annotated frames with bounding boxes  
- Detected actions & statistics (e.g., "Violence Detected")  
- Results saved to **Google Drive**  
- Displayed on the Streamlit dashboard as **"Normal" or "Violence Detected"**


## ğŸ§  What We Learnt

- âœ… Basics of Machine Learning (ML) & Deep Learning (DL)  
- ğŸ§  Neural Networks  
- ğŸ”„ Transformer Architecture  
- ğŸ‘ï¸â€ğŸ—¨ï¸ Fundamentals of Computer Vision  

---

## âœ… Conclusion

Vision Transformers (ViTs) offer a powerful approach for modern video surveillance. Leveraging ViTs allows:
- Real-time threat detection
- Enhanced object and activity understanding
- Actionable insights for decision-making

> However, ethical implementation is essential â€” privacy-preserving techniques and bias mitigation must be integrated to ensure responsible usage.

---

## ğŸ”® Future Works
 
- ğŸ”„ Continuous model refinement for surveillance  
- ğŸ“¡ Integration with smart alert systems  
- ğŸ” Strong emphasis on ethical use and data privacy
  
 ![Future Works Screenshot 1](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Future%20Works%201.png)

 ![Future Works Screenshot 2](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Future%20Works%202.png)

 ![Future Works Screenshot 3](https://github.com/bhuvanesh2235/-Surveillance-Using-Vision-Transformers-ViTs-/blob/main/Images/Future%20Works%203.jpg)
  

---

## ğŸŒ Possible Future Scope

- Enhanced anomaly detection in complex environments    
- Integration with retail POS and inventory systems  
- Real-time alerts for ORC and in-store violence  
- User-friendly dashboards for monitoring  
- Global standard compliance for AI surveillance systems


---


## ğŸ“œ License

This project is licensed under the MIT License 

